\section{Background Theory}
\label{sec:background_theory}
In this section, theory about different topics related to the thesis is presented. 

\subsection{Convolutional neural networks}
\input{convolutional_networks}


\subsection{Curriculum learning}
Curriculum learning is inspired by how humans learn, and by learning is highly organized through the education system and the use of a curriculum. Easier concepts tend to be introduced first. In terms of machine learning, this means presenting the classifier with easier samples first while training. To do so, a curriculum strategy has to be defined, which sorts the training set from easy to hard. Samples that are not near the decision boundary could be considered easy, for instance. Utilizing curriculum learning might lead to a faster convergence time, and the algorithm reaching a better local minima. Different works show that curriculum learning can achieve better generalization for many tasks \citep{Bengio_curriculumlearning} \citep{Kumar_self_paced_learning} \citep{Lu_self-paced_learning_diversity}.\\

A challenge for curriculum learning is defining a sorting measure that enables a curriculum strategy of gradually introducing harder training samples to the learner. This issue, and works related to curriculum learning, is further explored in Section \ref{sec:related_works}.\\


\subsection{Label noise}
\label{sec:background_label_noise}
There are several reasons for the presence of inconsistent labels in real-world datasets. For instance, the labeller was presented with insufficient information, or the dataset was automatically generated from a source with poor quality labels. Additionally, the samples could be ambiguous and therefore hard to label correctly by a human expert. Label noise, can in many cases, lead to negative consequences for a classifier. This can include reduced accuracy, increased model complexity, and more samples required for learning a target concept. Approaches for dealing with noisy labels can generally be divided into three groups: Noise-robust models, data cleansing methods and noise-tolerant algorithms \citep{Frenay_label_noise_survey}. These three groups are presented below.  \\

%\subsubsection{Types of noisy labels}
%Based on the noise distribution, three types of label noise can be identified according a extensive survey on label noise by \citep{Frenay_label_noise_survey}. The different types can be viewed in Figure ??\todo{Figur}. X is a vector of features or the data. For all types the observed variable Y* is assumed to depend the true label Y.  The E is a binary variable indicating if an labelling error has occurred. 

%Noisy completely at random (NCAR) model.

%Noisy at random (NAR) model. 

%Noisy not at random (NNAR) model


\subsubsection{Data cleansing methods}

Data cleansing methods are filtering techniques applied to the training data in order to remove noisy samples before training. Noisy labels are first identified and then either relabelled or removed. An obstacle encountered by these methods is that harmful mislabelled samples can be difficult to distinguish from informative, but hard samples. Another problem is that filtering often relies on predictions from a classifier to automatically identify mislabelled samples. Such filtering techniques also run the risk of removing too many samples from the training set, which can also cause harm to the accuracy. Voting ensembles of several classifiers have been suggested to further improve classification filtering.\\ 

Another filtering technique is to simply remove the class label of samples deemed suspicious, and employ semi-supervised learning. This way, the distribution of samples are preserved while simultaneously reducing the consequences of inconsistent labels.\\


\subsubsection{Noise-robust models}
Noise-robust models are algorithms that are naturally robust against label noise. Many algorithms have been shown to be less sensitive to label noise than others, especially to small amounts of label noise. This approach requires no noise modelling nor cleansing of the training set beforehand, because the algorithm is assumed to offer some robustness to mislabelled samples.\\

 Algorithms that utilize regularization techniques to avoid overfitting, can be considered more robust to label noise. This can include convolutional networks that utilize regularization schemes such as dropout or weight decay. For ensemble methods, bagging often gives better results than boosting when faced with noisy labels \citep{Dietterich_boosting_bagging}. The boosting algorithm AdaBoost, for example, combines many weak classifiers by iteratively re-weighting the training set to target samples the previous classifier had trouble predicting. Because mislabelled samples can be harder to predict, AdaBoost tends to put larger emphasis on mislabelled samples in later stages of learning, which can lead to increased sensitivity to label noise. In bagging methods, however, different subsets of the training data are used to create a diverse set of classifiers that are employed in a voting scheme. In this case, mislabelled samples can impact the performance positively, due to the increased variability in the classifiers produced by bagging.   


\subsubsection{Noise-tolerant algorithms}
In noise-tolerant approaches, existing algorithms are modified to be more robust towards label noise. This is often done by explicitly modelling a noise model during training. This way, a classifier learns to classify samples according to their true uncorrupted label, instead of the observed noisy label. Typically, the noise distribution and the model parameters are estimated simultaneously when training the classifier. \\

Techniques that incorporate label noise tolerance, such as particle competition, noise model estimation, bootstrapping, and co-training, will be further discussed in Section \ref{sec:related_works}.


\subsection{Evaluation metrics}
A common way to evaluate road extraction systems is by the quality measures,  correctness and completeness \citep{Wiedemann_road_evaluation}. These are closely related to precision and recall. Precision measures the fraction of true roads that are correctly detected, while recall is the fraction of predicted roads that are true roads. Because the label maps are not perfectly aligned with the images, it is also common to use a relaxed measure of precision and recall. This is accomplished by treating predicted road pixels within $p$ pixels of the the true road pixel as being correctly detected.
