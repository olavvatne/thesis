\section{Background Theory}
\label{sec:background_theory}
\subsection{Convolutional Neural Networks}
\input{convolutional_networks}
\label{sec:convolutional_networks_background}

\subsection{Label Noise}
\label{sec:background_label_noise}
There are several reasons for the presence of inconsistent labels in real-world datasets. For instance, the labeller was presented with insufficient information, or the dataset was automatically generated from a source with poor quality labels. Additionally, the samples could be ambiguous and therefore hard to label correctly by a human expert. Label noise, can in many cases, lead to negative consequences for a classifier. This can include reduced accuracy, increased model complexity, and more samples required for learning a target concept. Approaches for dealing with noisy labels can generally be divided into three groups: Data cleansing methods, noise-robust models, and noise-tolerant algorithms \citep{Frenay_label_noise_survey}. These three groups are presented below.  \\

%\subsubsection{Types of noisy labels}
%Based on the noise distribution, three types of label noise can be identified according a extensive survey on label noise by \citep{Frenay_label_noise_survey}. The different types can be viewed in Figure ??\todo{Figur}. X is a vector of features or the data. For all types the observed variable Y* is assumed to depend the true label Y.  The E is a binary variable indicating if an labelling error has occurred. 

%Noisy completely at random (NCAR) model.

%Noisy at random (NAR) model. 

%Noisy not at random (NNAR) model


\subsubsection{Data Cleansing Methods}

Data cleansing methods are filtering techniques applied to the training data in order to remove noisy samples before training. Noisy labels are first identified and then either relabelled or removed. An obstacle encountered by these methods is that harmful mislabelled samples can be difficult to distinguish from informative, but hard samples. Another problem is that filtering often relies on classifier predictions to automatically identify mislabelled samples. Such filtering techniques also run the risk of removing too many samples from the training set, which can also cause harm to the accuracy. Voting ensembles of several classifiers have been suggested to further improve classification filtering.\\ 

Another filtering technique is to simply remove the class label of samples deemed suspicious, and employ semi-supervised learning. This way, the distribution of samples are preserved while simultaneously reducing the consequences of inconsistent labels.\\


\subsubsection{Noise-robust Models}
Noise-robust models are algorithms that are naturally robust against label noise. Many algorithms have been shown to be less sensitive to label noise than others, especially to small amounts of label noise. This approach requires no noise modelling nor cleansing of the training set beforehand, because the algorithm is assumed to offer some robustness to mislabelled samples.\\

 Algorithms that utilize regularization techniques to avoid overfitting, can be considered more robust to label noise. This can include convolutional networks that utilize regularization schemes such as dropout or weight decay. For ensemble methods, bagging often gives better results than boosting when faced with noisy labels \citep{Dietterich_boosting_bagging}. The boosting algorithm AdaBoost, for example, combines many weak classifiers by iteratively re-weighting the training set to target samples the previous classifier had trouble predicting. Because mislabelled samples can be harder to predict, AdaBoost tends to put larger emphasis on mislabelled samples in later stages of learning, which can lead to increased sensitivity to label noise. In bagging methods, however, different subsets of the training data are used to create a diverse set of classifiers that are employed in a voting scheme. In this case, mislabelled samples can impact the performance positively, due to the increased variability in the classifiers.   


\subsubsection{Noise-tolerant Algorithms}
In noise-tolerant approaches, existing algorithms are modified to be more robust towards label noise. This is often done by explicitly modelling a noise model during training. This way, a classifier learns to classify samples according to their true uncorrupted label, instead of the observed noisy label. Typically, the noise distribution and the model parameters are estimated simultaneously when training the classifier. \\

Techniques that incorporate label noise tolerance, such as particle competition, noise model estimation, bootstrapping, and co-training, will be further discussed in Section \ref{sec:related_works}.

\subsection{Curriculum Learning}
Curriculum learning is inspired by how humans learn, and that learning typically is highly organized. For instance, by the use of a curriculum in educational institutions. Easier concepts tend to be introduced first. In terms of machine learning, this means presenting the classifier with easier samples first while training. To do so, a curriculum strategy has to be defined, which sorts the training set from easy to hard. Samples that are not near the decision boundary could be considered easy, for instance. Utilizing curriculum learning might lead to a faster convergence time, and the algorithm reaching a better local minima. Different works show that curriculum learning can achieve better generalization for many tasks \citep{Bengio_curriculumlearning} \citep{Kumar_self_paced_learning} \citep{Lu_self-paced_learning_diversity}.\\

A challenge for curriculum learning is defining a sorting measure that enables a curriculum strategy of gradually introducing harder training samples to the learner. This issue, and works related to curriculum learning, is further explored in Section \ref{sec:related_works}.\\

\subsection{Road Extraction by Machine Learning}
Road extraction is a part of the field of Photogrammetry. The field involves technology for map production and measurements of objects in images. As digital acquisition systems for capturing aerial images have become commonplace, the availability of high resolution aerial images have increased. Coupled with the increasing need for detailed spatial information in \ac{GIS} databases and production of digital maps, a lot of approaches for automatic object extraction from aerial imagery has been suggested. A reliable and accurate detection system could be beneficial in terms of increased levels of details, while reducing the cost associated with map production.\\

There are three distinctive approaches for extracting objects from aerial imagery. Manual, semi-automatic and automatic methods. The semi-automatic approach integrates computer vision techniques and machine learning into the workflow of skilled human labellers. For instance, Google's Ground Truth project employs skilled operators which utilize advanced software tools to improve the accuracy of Google's map products \citep{Ground_truth}.\\

To do automatic road extraction, supervised learning is often employed. This requires a training dataset of aerial image examples and labels. The labels for road extraction are usually binary images that shows the ground truth of roads. Creating the label images by manually labelling aerial imagery would be prohibitively expensive, which is why ground truth labels are often generated from existing map data. Figure \ref{fig:background_dataset_example} shows an example of aerial image and label typically found in a road extraction dataset.\\

\begin{figure}
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\linewidth]{figs/background_theory_example_data.png}
\caption{Aerial image} \label{fig:background_dataset_example_data}
\end{subfigure}
\hspace*{\fill} % separation between the subfigures
\begin{subfigure}{0.40\textwidth}
\includegraphics[width=\linewidth]{figs/background_theory_example_label.png}
\caption{Label image} \label{fig:background_dataset_example_label}
\end{subfigure}
\caption[Example from the Norwegian Roads Dataset]{Image and label example from the training set of the Norwegian Roads Dataset.} \label{fig:background_dataset_example}
\end{figure}

From these large training set images, smaller training set patches are extracted. The supervised learning algorithm is given a patch dataset $d$ containing $N$ training examples in the form $d=\{(s_1, m_1),...,(s_N, m_N)\}$, where $s_i$ is an aerial image patch and $m_i$ is the corresponding ground truth label. Examples of aerial image patches and labels can be found in Figure \ref{fig:examples_background}. The learning algorithm's task is to learn a suitable mapping from the input space of aerial imagery to the output space of road ground truth. For neural networks, this mapping is typically learned by minimizing the cross-entropy loss by gradient descent optimization.\\

\begin{figure}
\begin{center}
\includegraphics[width=1\columnwidth]{figs/examples.png}
\caption[Patch dataset examples]{Aerial image and label examples from a patch dataset. The patches originate from the Norwegian Roads Dataset. Each label indicates the road ground truth from the center location of the aerial patch.}
\label{fig:examples_background}
\end{center}
\end{figure}

 The resulting classifier has hopefully extracted some useful patterns from the training data, which enables it to generalize to the task of road extraction. This is verified by computing the \ac{MSE} on a test set, containing examples not seen during training. The machine learning approach for road extraction, should therefore be able to train algorithms from data which can predict the ground truth reasonable well for new unseen aerial image patches. \\

\subsection{Evaluation Metrics}
A common way to evaluate road extraction systems is by the quality measures,  correctness and completeness \citep{Wiedemann_road_evaluation}. These are closely related to precision and recall. Precision measures the fraction of true roads that are correctly detected, while recall is the fraction of predicted roads that are true roads. Because the label maps are not perfectly aligned with the images, it is also common to use a relaxed measure of precision and recall. This is accomplished by treating predicted road pixels within $p$ pixels of the the true road pixel as being correctly detected, and true roads within $p$ of a predicted road pixel as properly recalled. The slack parameter $p$ is often set to 3 pixels \citep{Mnih_roads_high_res_aerial_images}.

