\section{Contributions}~\label{cont}
\label{sec:Contributions}
This thesis sought to test approaches for dealing with noisy labels in real-world datasets. This is an compelling inquiry in the field of machine learning, where the trend of using deep neural networks with a huge number of adjustable parameters, requires large training sets to generalize well. There is an abundance of existing data available online, which can be used for learning. Unfortunately, in many cases this data lacks accurate labels for supervised training. To manually label the data can be expensive, and very time consuming in many domains, such as transcribing speech for speech recognition, and tracing ground truth for semantic segmentation. Automatically generating datasets from existing data sources are a quick and economical solution, but can result in datasets with a lot of label noise.\\

The problem of label noise, was therefore tackled in this thesis by testing two different methods. Bootstrapping modifies the loss function, in order to reduce the impact of inconsistent labels. Curriculum learning modifies the training regime by sorting the training set into stages from ``easy" to ``hard" examples. The sorting mechanism, or curriculum strategy is based on measuring inconsistencies between labels and teacher predictions. Coincidentally, ``hard" examples often have inconsistent labelling, and are therefore more likely to be presented at a later stage of optimization if the dataset is organized according to this curriculum strategy. In effect, inconsistent examples are a less frequent occurrence in the first stage of the curriculum dataset.\\
 
The curriculum strategy can most likely be applied to tasks in other domains, since the example difficulty estimator $d(y,q)$ does not rely on any intrinsic features of image data. However, the effectiveness of this curriculum strategy has not been verified for other domains than road detection in aerial images.\\

The thesis found that bootstrapping did show some robustness towards label noise. The effect was however not of any statistical significance. Furthermore, the base network also performed surprising well for very high rates of omission noise.\\

Curriculum learning demonstrated consistently improved generalization accuracy in the experiments. The improved accuracy, was observed both for the Massachusetts Roads Dataset, as well as for the Norwegian Roads Dataset. The experiments also showed that only changing the example distribution of the first stage training set, affected the final outcome of the training procedure.\\

