\section{Semantic Segmentation with Convolutional Neural Network}
\label{sec:network}
This section will present the convolutional neural network in detail. \todo[inline]{Better and a slightly longer introduction to section}

\subsection{Patch-based architecture}
\todo[inline]{Outline what this thing actually predict. Patch based approach}
\todo[inline]{Input bigger than output. Context, etc}
\todo[inline]{Explain layering etc. show image}

The system is based on the deep neural network outlined by \cite{Mnih_aerial_images_noisy}. The network have three convolutional layers and two fully connected layers. This network architecture is depicted in Figure \ref{fig:conv}. After the network is trained, it can predict whether or not roads are present in a $16 \times 16$ pixel area contained in the center of a $64 \times 64$ aerial image patch. The input patch is considerably larger than the output patch, so that the network can better utilize the context in the image. \\

The first layer perform convolution using $13 \times 13$ kernels, and outputs in total 64 feature maps. Only the first layer utilize max pooling, which reduces the number of inputs to the next layer as well as introducing some translational invariance to the model. The kernel size in the second and third layer are currently $4 \times 4$ and $3 \times 3$, respectably. The output of the third convolutional layer is used as input to a fully connected neural network with a single hidden layer and an output layer. The latter contains 256 units where each output is the probability of a pixel representing a road.\\

\begin{figure}
\begin{center}
\includegraphics[width=1\columnwidth]{figs/network/Filter_unblurred.png}
\caption[Visualization of filter map]{Visualization of filter maps from the first convolutional layer of a trained network.}
\label{fig:convoluional_first_layer_visualization}
\end{center}
\end{figure}

\begin{table}[htp]
\caption{Hyperparameters for \ac{CNN}}
\begin{center}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{+l ^l ^l}\hline
\rowstyle{\bfseries}
  Parameter & Description & Value\\\hline
  $K_i$ & Number of kernels for convolutional layer i & 64, 112, 80 \\
  $CLF_i$ & Filter size of convolutional layer $i$ & (13,13),(4,4),(3,3) \\
  $CLS_i$ & Stride amount of convolutional layer $i$ & (4,4),(1,1),(1,1) \\
  $CLP_i$ & Pool size of convolutional layer $i$ & (2,2),(1,1),(1,1) \\
  Cost function & Function that is minimzed each iteration & Cross entropy \\
  Epochs & How many epochs \ac{CNN} will train for. & 100 \\
  $\theta_i$ & Transfer function for each value & Leaky ReLU x4, sigmoid x1 \\
  $h$ & Number of neurons in hidden layer. & 4096 \\
  $p_i$ & Dropout rate for a layer $i$ & 1.0, 0.9, 0.8, 0.5, 1.0 \\
  $a$ & Learning rate & 0.0014 \\
  $L_2$ & Weight decay & 0.0001 \\
  $m$ & Momentum & 0.9 \\
  $b$ & Batch size & 64 \\\hline
\end{tabular}
\end{adjustbox}
\end{center}
\label{tab:curriculum_parameters}
\end{table}

\subsection{Optimization}
\todo[inline]{Really bad, explanation. But something}
%\url{http://cs231n.github.io/neural-networks-3/}
%http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}
\todo[inline]{Mathematical detail}
\todo[inline]{paper}
The model parameters are optimized with a special form of \ac{SGD}, called Nesterov momentum stochastic gradient decent, and can help the network reach convergence faster compared to standard \ac{SGD}. The standard momentum approach extend the gradient update step, by introducing velocity and friction. The loss can be interpreted as a hilly error surface where loss optimization can be viewed as a particle gaining and losing velocity while interacting with the landscape. When the particle or loss optimization is gaining velocity, it will stop doing steepest decent, and result in a smoother decent with less oscillations. Basically, instead of using the gradient to move in the landscape, the gradient will influence the velocity. Unlike standard momentum, the Nesterov method \todo{Need better word than that} first makes a step in the direction of the previous accumulated gradient, and then makes a correction using the current gradient. \todo{Is this true?}\\

Furthermore, the system also suppoert RMSProp which keeps a running average of the gradient magnitude for every weight. This is used to adaptively adjust the learning rate of each weight. Compared to regular \ac{SGD}, this will result in a faster convergence. The system also support regular \ac{SGD}. \todo{Paper detailing RMSprop}\\ 

\todo[inline]{Learning and negative log likelihood?. Optimization of the loss. So the loss is negative log likelihood}

\subsection{Regularization}
\todo[inline]{Dropout}
\todo[inline]{L2 regularization}
\todo[inline]{Early stopping}
\todo[inline]{Leaky ReLu}
To avoid overfitting the training data, and hopefully achieve better generalization, different regularization schemes are applied during optimization, such as L2 weight decay, early stopping, and dropout. The first applies a weight penalty to prevent weights from growing large. The second stops the optimization process when performance on the validation set starts to consistently decrease. This is an indication of the model starting to overfit the training set. Dropout forces the units to rely less on each other, by randomly disabling half of the units in the network during training. This encourage units to encode independently useful information, since dropout penalize co-adaptation between units.\\


\subsection{Data preprocessing}
\todo[inline]{Rotation of aerial images}
\todo[inline]{Contrast normalization}
\todo[inline]{Flipping vertical and horizontal}
\todo[inline]{Class normalization. 50/50}

Before training occurs, a patch dataset suitable for the model is constructed. Each data and label image is rotated by a random amount, and a predefined number of image and label patches are extracted from the images. Before adding the sample to the training set, contrast normalization is applied. The mean pixel value in a patch is subtracted from each pixel, and divided by the standard deviation found for all pixels in the dataset.\\

\todo[inline]{Have to justify model layering. 256 output? why 64x64 input images why? Context. }
\todo[inline]{Large datasets, swap from memory to gpu (maybe)}