\section{System Overview}
\label{sec:systemOverview}
\todo[inline]{Super overview.
Dataset loader (Pre generated or otherwise) Convolutional neural network. Storage. webGUI and in file
}
\todo[inline]{In big terms, talk about finding roads, but as mnih. Datasets contain two label noise. Investigate ways of mitigating the impact label noise have. Also the aerial image datasets contain large variety of images. Some are much harder. Epecially when inconsistent labelling. Curriculum learning. }

\subsection{Data loader}
\todo[inline]{Data loader and network loosely coupled. Can adapt system to other image problems easily. All hyperparameters can be changed in a config file. From number of layers, epochs etc etc. What backpropagation method}

\subsection{Convolutional neural network}
\todo[inline]{Reasons to use CNN. Related work , compelling results. CNN extract features. Suited for image task. }
\todo[inline]{Have to justify model layering. 256 output? why 64x64 input images why? Context. }
\begin{itemize}
\item leaky relu
\item dropout
\item sdg nesterov
\item L2 regularization
\item Large datasets, swap from memory to gpu (maybe)
\item Curriculum stage loading and swapping.
\item Bootstrapping loss
\item Curriculum teacher and dataset example evaluator.
\end{itemize}

The road extraction system was written in Python, and uses the open source library Theano. Theano enables the user to define and evaluate mathematical expressions involving tensors. The library implements several useful features for developing \ac{CNN}s, such as back-propagation, convolution, and max pooling. Training deep neural networks on a \ac{GPU} can be considerably faster than on a \ac{CPU}. Theano can utilize both the \ac{CPU} and \ac{GPU} without making any modifications to the code.\\

The system is based on the deep neural network outlined by \cite{Mnih_aerial_images_noisy}. The network have three convolutional layers and two fully connected layers. This network architecture is depicted in Figure \ref{fig:conv}. After the network is trained, it can predict whether or not roads are present in a $16 \times 16$ pixel area contained in the center of a $64 \times 64$ aerial image patch. The input patch is considerably larger than the output patch, so that the network can better utilize the context in the image. \\

The first layer perform convolution using 16x16 kernels, and outputs in total 64 feature maps. Only the first layer utilize max pooling, which reduces the number of inputs to the next layer as well as introducing some translational invariance to the model. The kernel size in the second and third layer are currently $4 \times 4$ and $3 \times 3$, respectably. The output of the third convolutional layer is used as input to a fully connected neural network with a single hidden layer and an output layer. The latter contains 256 units where each output is the probability of a pixel representing a road.\\

To avoid overfitting the training data, and hopefully achieve better generalization, different regularization schemes are applied during optimization, such as L2 weight decay, early stopping, and the dropout technique. The first applies a weight penalty to prevent weights from growing large. The second stops the optimization process when performance on the validation set starts to consistently decrease. This is an indication of the model starting to overfit the training set. Dropout forces the units to rely less on each other, by randomly disabling half of the units in the network during training. This encourage units to encode independently useful information, since dropout penalize co-adaptation between units.\\

The model parameters are optimized with a special form of \ac{SGD}, called RMSProp. RMSProp keeps a running average of the gradient magnitude for every weight which is used to adaptively adjust the learning rate of each weight. Compared to \ac{SGD}, this will result in a faster convergence. Other optimizers, such as Nesterov momentum, have also been implemented.\\

Before training occurs, a patch dataset suitable for the model is constructed. Each data and label image is rotated by a random amount, and a predefined number of image and label patches are extracted from the images. Before adding the sample to the training set, contrast normalization is applied. The mean pixel value in a patch is subtracted from each pixel, and divided by the standard deviation found for all pixels in the dataset.\\

\subsection{Web Interface}