\section{Future Work}
\label{sec:futureWork}
This section presents future work, such as how to further verify the proposed curriculum strategy and bootstrapping loss function. In addition, this section will suggest further improvements for the road detection system.\\

The most compelling improvement of the road detection system, is by incorporating \ac{CRF} or a post processing neural network, as described in Section \ref{sec:related_works}. This was demonstrated by \cite{Kluckner_semantic_height} and \cite{Mnih_aerial_images_noisy} \todo{Correct cites?}, and yielded improvements in precision and recall and accuracy.\todo{Expand here?} \\

To use the road predictions further in GIS applications, the binary prediction images should be converted into road-line vectors. To do this, the predictions images has to be combined, and the resulting segmentation image must be cleaned. Methods from computer vision might be applicable for this work. For instance in \citep{Song_road_extraction_svm}, shape descriptions was extracted from the segmentation images, which can be used to measure density and shape index. Based on these values, shapes which have measurements not characteristic of roads can be removed by a threshold operation. In addition, morphological operations, such as thinning or skeletonization , can be used to reduce the segmented road regions down to one pixel thick lines. \todo{How to convert into vectors}\\

Another potential improvement of the results, is by finding better hyperparameters. The experiments testing the performance of the road detection system, showed that the model capacity was initially constrained. Increasing the number of adjustable weights in the convolutional layers improved the precision and recall breakeven point substantially \todo{What techniques to test}. Combining dropout with max-norm regularization instead of L2 weight decay could also be interesting, since this configuration achieved better test classification error in \citep{Srivastava_dropout}.\\

The bootstrapping methods showed promise, but the results were not significant in the experiments conducted. This might be related to ill-suited parameters. Further testing of parameter configurations should be considered. In addition, the bootstrapping method should be tested with increasing levels registration noise. The confident bootstrapping loss function could also be explored further. An interesting comparison of the bootstrapping methods, is mapping the relationship between decreasing parameter $\beta$ and their resulting performances. Based on the few experiments conducted, it seems that confident bootstrapping is less negatively affected by low $\beta$ parameters.\todo{BAD paragraph}\\


There are some unresolved questions regarding curriculum learning, and the proposed curriculum strategy. For instance, is it worth including examples with a very high difficulty estimate? And how does data cleansing approach described in Section \ref{sec:BackgroundAndMotivation}, compare to curriculum learning? The thesis also does not properly determine how experienced a teacher model has to be, to create an effective curriculum dataset. Further tests could illuminate the relationship between teacher model competency and the effectiveness of curriculum learning.  \\

The curriculum learning approach should also be tested on a deep neural network trained on a very large dataset. This could alternatively be tested by mapping the impact of curriculum learning for increasing training set sizes. The proposed strategy should also be compared to \ac{SPL}\citep{Kumar_self_paced_learning}, which internalize the curriculum mechanism in it's loss function. Both methods have a similar definition of what constitutes an easy examples.\todo{Do they, EM algorithm. Not individual examples but groups or something?}\\

Furthermore, \cite{Lu_self-paced_learning_diversity} illustrated the need for balancing diversity and easiness in curriculum learning. The \ac{SPL} approach is extended by a preference for both easy and diverse examples. This could potentially be done for the proposed curriculum strategy as well. This could be done by unsupervised learning techniques, such as clustering, which can organize the images into groups based on their similarity. The curriculum dataset can than be constructed with an equal representation of every cluster group. This might allow reducing the difficulty threshold $D_0$, without negatively impacting the performance.\\

In summary, the current version of the curriculum strategy was effective for two different datasets containing aerial imagery. However, the method should be tested for tasks in other domains as well. This might properly determine whether the proposed curriculum strategy can be generally applicable.\\
 

