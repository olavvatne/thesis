\section{Future Work}
\label{sec:futureWork}
\todo[inline]{How to extend yout eotk. Directions that became obvious during work}
\todo[inline]{Possible solutions for limitations in the work conducted}
incorporate conditional random fields. Will yield further improvements.
\todo[inline]{Some larger tests but runtime too large for extensive testing with these quantities}
The current system needs to be further tested, and extensions are required in order to evaluate the research questions. For the system itself, there are two important improvements. First, the system must implement precision and recall. This enables comparisons of other similar systems created for road detection. Additionally, the system performance can be displayed using precision-recall curves. To create this type of plot, threshold operations are applied to the model prediction probabilities for different values between $0 \leq T \leq 1$. This results in values that shows the trade-off between precision and recall in the system. Second, a scheme for gradually swapping out the data on the \ac{GPU} needs to be implemented. The bottleneck for the current system is the limited size of the training set, caused by the insufficient memory size of the \ac{GPU}. Currently, the training set can only hold 30000 samples, when training on a \ac{GPU}. This is not enough for a classifier to learn the variability present in aerial images. In comparison, \cite{Mnih_roads_high_res_aerial_images} utilized 1.2 million training samples.\\

The road detection system consists of a \ac{CNN}. This was shown, by \cite{MnihThesis}, to give better performance than locally connected neural networks with untied weights. However, there are still parts of the network architecture worth exploring further. For instance, can increasing the number of convolutional layers improve the network's ability to extract features? Tweaking the kernel sizes of the different layers could also be beneficial, and if an input layer connected to a neighbourhood larger than a $64 \times 64$ pixels can better resolve ambiguous in the data. \cite{MnihThesis} also suggested adapting the loss function to maximize the area under the precision-recall curve. Furthermore, different optimization techniques, such as Nesterov momentum and RMSProp, could be compared.\\

One of the most compelling ways of improving performance for road detection, is utilizing structured output prediction methods. Several studies \citep{Kluckner_semantic_height} \citep{LeCun_semantic} \citep{Mnih_roads_high_res_aerial_images} have shown that employing a smoothness prior, by taking neighbouring predictions into account, can significantly improve generalization in semantic segmentation tasks. Implementing either \ac{CRF} or the post-processing neural network in the road detection system will therefore be considered.\\

In terms of evaluating the system, precision-recall curves will enable comparison to other systems. The system will also be trained using the Massachusetts Roads Dataset, which other road detection systems have utilized for training \citep{MnihThesis}\citep{saito_building_and_roads}. By training on the same dataset, the ability of the classifiers can more easily be compared. Furthermore, the system will also be evaluated on the Norwegian Roads Dataset. An interesting experiment would be to train the system using one of the datasets, and see what performance is achieved by the other dataset. The datasets contain two very separate areas, but also depict roads with relatively similar appearance. This might indicate how well the system captures the variability in aerial images. \\

The first research question involves reducing the effect of inconsistent labels when training a classifier. The bootstrapping approach presented by \cite{Reed_noisy_labels_bootstrapping} will be evaluated for road detection. Whereas the loss functions presented by \citep{Mnih_aerial_images_noisy} require a noise distribution model,  bootstrapping utilize a   convex combination between the classifier's prediction and the label. This approach seems to be more generally applicable, and has been tested for different tasks.\\

 An interesting improvement to this approach is to learn a time-dependent parameter for how much the classifier's own prediction should be trusted. The parameter should, at the start of training, weight the convex combination more in favor of the label. While in later stages of training, the parameter can favor the classifier's predictions more, because they have become more accurate.\\

It is important to demonstrate that the approach offers robustness to different amounts of label noise. This can be done by artificially introducing label noise in samples of road detection datasets. Omission noise can be simulated by removing a fraction of the ground truth in the label images, while registration noise can be introduced by shifting subsets of label images by a certain amount of pixels. Classifiers with the bootstrapping extension can be trained on these modified datasets, and compared to the performance achieved from baseline classifiers. The performances can then be compared at different noise levels, and reveal whether or not the technique offers any robustness towards noisy labels. Similar experiments have been conducted by \citep{Sukhbaatar_noisy_network_learning} and \citep{Reed_noisy_labels_bootstrapping} for a variety of datasets. \\

The second research question will investigate what effect a curriculum strategy can have on the road detection system's precision and recall. An interesting curriculum strategy, mentioned by \cite{Bengio_curriculumlearning}, is creating an easy-to-hard ordering of samples according to how noisy the samples are. This particular curriculum strategy might assist the bootstrapping technique, as well as being applicable for datasets containing images. A classifier is trained to a decent level for road detection, and in turn, is used to create a simple and complex dataset. Samples that are confidently and correctly predicted are considered easy and put in the simple dataset. The samples that are confidently predicted, but wrong, are assumed to be inconsistent, and therefore put in the complex dataset. The inconsistent examples will then have a higher probability of being presented later in the training procedure, when the model predictions have become more trustworthy. The convex combination of the bootstrapping approach can then be tuned more in favor of the predictions, which might avoid the negative consequences of inconsistent labelling.  It could be interesting to determine whether this curriculum strategy is beneficial for the bootstrapping technique in any way.\\

A curriculum strategy could also be defined based on image characteristics. For instance, aerial images of remote areas generally presents less complexity and ambiguity. However, this would be a more problem-specific strategy. \\ 

Alternatively, the \ac{SPL} or the \ac{SPLD} method \citep{Kumar_self_paced_learning} \citep{Lu_self-paced_learning_diversity} can be implemented in the road detection system. These methods have the advantage of not being problem-specific. In addition, the model controls the pace of learning, and there is no need to construct a fixed sequence of samples beforehand. These methods have also been evaluated for real-world datasets, and seem to work well for images. \\ 

To evaluate curriculum learning, the road detection system could be trained, using both an unaltered training scheme and with a curriculum strategy. The results can then be compared, in order to determine whether curriculum learning can achieve better generalization for road detection.\\


In summary, the loss function of the road detection system will be modified, and an alternative training regime will be used for training. To measure the effect of these modifications, the system will be compared to a baseline system, and previous results achieved by similar systems.